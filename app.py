import streamlit as st
import mysql.connector
import time
import pandas as pd
import os

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Benchmark MySQL", page_icon="üèéÔ∏è", layout="wide")

# --- CABE√áALHO INSTITUCIONAL ---
col_logo, col_header_text = st.columns([1.5, 5], vertical_alignment="center")

with col_logo:
    try:
        st.image("image_7.png", use_container_width=True) 
    except FileNotFoundError:
        st.warning("Imagem 'image_7.png' n√£o encontrada.")

with col_header_text:
    st.markdown("""
    ## ALGORITMOS E ESTRUTURA DE DADOS II
    **Professora:** Dana Tomazett\n
    **Aluno:** Wesley Dias Fr√≥es - **Matr√≠cula:** 20232243038
    """, unsafe_allow_html=True)

st.divider() 

# --- TEXTO INTRODUT√ìRIO ---
st.markdown("""
Este aplicativo visa demonstrar o uso dos tr√™s algoritmos de pesquisa: 
* Pesquisa Sequencial, 
* Pesquisa Indexada,
* Pesquisa por HashMap
Avaliando o tempo de resposta de cada um deles.

Para realizar a demonstra√ß√£o, digite o **Nome Completo** ou o **CPF** na caixa de pesquisa e clique no bot√£o **Buscar**.
*Nota 1: Para demonstrar a efici√™ncia O(1) do HashMap, a busca deve ser exata.*

Visualize a tabela de dados na se√ß√£o √Årea acad√™mica caso n√£o saiba o que pesquisar!
""")

# --- CONEX√ÉO COM O BANCO AIVEN ---
def get_connection():
    return mysql.connector.connect(
        host="mysql-3455cc47-wesleyfroes-5e7b.k.aivencloud.com",
        user="avnadmin",
        password="AVNS__rOT2E8RQkt_4-TPrSg", 
        database="dana", 
        port=27950
    )

# --- CARREGAR DADOS PARA MEM√ìRIA ---
@st.cache_resource
def load_hashmap():
    conn = get_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT ID, Nome, CPF FROM dados")
    result = cursor.fetchall()
    conn.close()
    
    hash_map = {}
    for row in result:
        if row[1]: hash_map[row[1]] = row[0]
        if row[2]: hash_map[row[2]] = row[0]
            
    return hash_map

try:
    with st.spinner('Carregando dados para mem√≥ria RAM...'):
        hash_db = load_hashmap()

except Exception as e:
    st.error(f"Erro de conex√£o: {e}")
    st.stop()

st.divider() 

# --- INPUT DO USU√ÅRIO ---
# CSS Injetado para dar estilo de "Cart√£o" ao formul√°rio (Fundo + Borda)
st.markdown("""
<style>
    [data-testid="stForm"] {
        background-color: var(--secondary-background-color);
        padding: 20px;
        border-radius: 10px;
        border: 1px solid rgba(250, 250, 250, 0.1);
    }
</style>
""", unsafe_allow_html=True)

# Usamos st.form para permitir que a tecla ENTER submeta a busca
with st.form(key='search_form'):
    col_search, col_btn = st.columns([3, 1], vertical_alignment="bottom") 
    with col_search:
        termo = st.text_input("Digite NOME COMPLETO ou CPF:", placeholder="Ex: Augusto Sampaio ou 760.142.958-01")
    with col_btn:
        # Em um formul√°rio, o bot√£o deve ser form_submit_button
        executar = st.form_submit_button("üîç Buscar", type="primary", use_container_width=True)

# Exibe a mensagem de status do sistema logo abaixo do bot√£o/formul√°rio
if 'hash_db' in locals():
    st.success(f"‚úÖ Sistema Online. {len(hash_db)} chaves de busca em mem√≥ria (Indexando Nomes + CPFs).")

if executar:
    if not termo:
        st.warning("Digite algo para buscar.")
    else:
        tempos = {}
        dados_encontrados = None
        colunas_retornadas = []
        
        # 1. BUSCA SEQUENCIAL (O(n))
        conn = get_connection()
        cursor = conn.cursor()
        start = time.perf_counter()
        
        sql_sequencial = f"SELECT * FROM dados WHERE Nome = '{termo}' OR CPF = '{termo}'"
        cursor.execute(sql_sequencial)
        _ = cursor.fetchall()
        tempos['Sequencial'] = time.perf_counter() - start
        conn.close()

        # 2. BUSCA INDEXADA (O(log n))
        conn = get_connection()
        cursor = conn.cursor()
        start = time.perf_counter()
        
        sql_indexada = f"SELECT * FROM dados WHERE Nome = '{termo}' OR CPF = '{termo}'"
        cursor.execute(sql_indexada)
        dados_encontrados = cursor.fetchall()
        if cursor.description:
            colunas_retornadas = [i[0] for i in cursor.description]
            
        tempos['Indexada'] = time.perf_counter() - start
        conn.close()

        # 3. HASHMAP (O(1))
        start = time.perf_counter()
        _ = hash_db.get(termo)
        tempos['HashMap'] = time.perf_counter() - start

        # --- EXIBI√á√ÉO ---
        if dados_encontrados:
            st.success(f"‚úÖ Registro Localizado! ({len(dados_encontrados)} ocorr√™ncias)")
            df_resultado = pd.DataFrame(dados_encontrados, columns=colunas_retornadas)
            st.dataframe(df_resultado, hide_index=True, use_container_width=True)
            
            st.divider()
            st.write("### ‚è±Ô∏è Tempos de Execu√ß√£o")
            
            # M√©tricas
            c1, c2, c3 = st.columns(3)
            c1.metric("1. Sequencial", f"{tempos['Sequencial']:.5f}s")
            c2.metric("2. Indexada", f"{tempos['Indexada']:.5f}s")
            c3.metric("3. HashMap", f"{tempos['HashMap']:.8f}s")
            
            # Gr√°fico
            df_chart = pd.DataFrame([
                {"M√©todo": "1. Sequencial", "Tempo (s)": tempos['Sequencial']},
                {"M√©todo": "2. Indexada", "Tempo (s)": tempos['Indexada']},
                {"M√©todo": "3. HashMap", "Tempo (s)": tempos['HashMap']}
            ])
            st.bar_chart(df_chart, x="M√©todo", y="Tempo (s)", color="#00a8ff")

            # --- RANKING DE PERFORMANCE ---
            # Ordena do mais r√°pido (menor tempo) para o mais lento
            ranking = sorted(tempos.items(), key=lambda item: item[1])
            
            st.info(f"""
            **üèÜ Ranking de Performance (Do mais r√°pido para o mais lento):**
            
            1. ü•á **{ranking[0][0]}** - {ranking[0][1]:.6f}s
            2. ü•à **{ranking[1][0]}** - {ranking[1][1]:.6f}s
            3. ü•â **{ranking[2][0]}** - {ranking[2][1]:.6f}s
            """)

        else:
            st.error(f"‚ùå '{termo}' n√£o encontrado. Lembre-se de digitar o Nome Completo ou CPF exato.")

# --- √ÅREA ACAD√äMICA ---
st.divider()
st.subheader("üéì √Årea Acad√™mica")
st.write("Recursos para valida√ß√£o do projeto.")

# 1. TABELA DE DADOS (PRIMEIRO)
if st.toggle("üìÇ Ver Tabela de Dados (Amostra)"):
    with st.spinner("Buscando dados no banco..."):
        conn = get_connection()
        df_dados = pd.read_sql("SELECT * FROM dados", conn)
        st.info(f"Exibindo todos os {len(df_dados)} registros da base.")
        st.dataframe(df_dados, hide_index=True)
        conn.close()

st.write("") 

# 2. RELAT√ìRIO T√âCNICO (SEGUNDO)
if st.toggle("üìÑ Ver Relat√≥rio T√©cnico"):
    st.markdown("""
    ### Relat√≥rio T√©cnico: Desenvolvimento de Benchmark de Algoritmos de Busca
    **Aluno:** Wesley Dias Fr√≥es  
    **Disciplina:** Algoritmos e Estrutura de Dados II  
    **Professora:** Dana Tomazett

    #### 1. Introdu√ß√£o
    Este projeto tem como objetivo demonstrar, na pr√°tica, a aplica√ß√£o da teoria de complexidade de algoritmos (Nota√ß√£o Big O - ferramenta matem√°tica usada para descrever o desempenho de um algoritmo, especialmente como sua complexidade de tempo ou espa√ßo escala conforme o tamanho da entrada cresce.). Foi desenvolvida uma aplica√ß√£o Web capaz de comparar o desempenho de tr√™s m√©todos de busca de dados (Sequencial, Indexada e HashMap) em um ambiente de banco de dados real hospedado na nuvem.

    #### 2. Etapa 1: Modelagem e Prepara√ß√£o dos Dados (Local)
    O projeto iniciou-se com a estrutura√ß√£o da massa de dados necess√°ria para os testes.
    * **Origem:** Os dados brutos foram organizados inicialmente em planilhas Excel e convertidos para o formato `.csv`.
    * **Modelagem Local:** Utilizando o **MySQL Workbench**, foi criado um banco de dados local. A importa√ß√£o dos dados `.csv` permitiu povoar a tabela `dados` com mais de 5.000 registros, contendo informa√ß√µes como Nome, CPF, Endere√ßo e Telefone. Esta etapa garantiu a integridade e a tipagem correta das colunas antes da migra√ß√£o para a nuvem.

    #### 3. Etapa 2: Migra√ß√£o para a Nuvem (Cloud Database)
    Para que a aplica√ß√£o fosse acess√≠vel via internet, o banco de dados n√£o poderia residir apenas no computador local (`localhost`).
    * **Provedor Escolhido:** Utilizou-se a plataforma **Aiven**, um servi√ßo de DBaaS (Database as a Service), para hospedar uma inst√¢ncia MySQL gerenciada.
    * **Migra√ß√£o:** Atrav√©s do MySQL Workbench, foi realizada uma conex√£o remota com o servidor da Aiven. O *dump* (backup) do banco local foi executado no servidor remoto, replicando a estrutura da tabela e os dados na nuvem.
    * **Indexa√ß√£o:** Nesta fase, foi essencial garantir a cria√ß√£o de √≠ndices (B-Tree) nas colunas de busca para diferenciar a performance da busca indexada em rela√ß√£o √† busca sequencial.

    #### 4. Etapa 3: Desenvolvimento da L√≥gica (Python + Streamlit)
    O "c√©rebro" da aplica√ß√£o foi desenvolvido em Python, utilizando a biblioteca **Streamlit** para criar o Frontend e o Backend simultaneamente.
    * **Conex√£o:** Implementou-se o conector `mysql-connector-python` para estabelecer a comunica√ß√£o segura entre a aplica√ß√£o e o banco Aiven.
    * **Implementa√ß√£o dos Algoritmos:**
        1. **Busca Sequencial:** Simulada atrav√©s de queries SQL que percorrem a tabela linearmente (Full Table Scan).
        2. **Busca Indexada:** Utiliza os recursos nativos de indexa√ß√£o do MySQL para localiza√ß√£o r√°pida.
        3. **HashMap:** Implementada carregando os dados (ID, Nome e CPF) para a mem√≥ria RAM do servidor (Dicion√°rio Python) na inicializa√ß√£o do sistema, permitindo acesso instant√¢neo.
    * **Funcionalidades Extras:** Foram adicionados gr√°ficos comparativos, exibi√ß√£o dos dados retornados e uma "√Årea Acad√™mica" que permite ao avaliador inspecionar o c√≥digo-fonte e a tabela de dados em tempo real.

    #### 5. Etapa 4: Versionamento e Prepara√ß√£o para Deploy
    Para publicar o projeto, utilizou-se o **GitHub** como reposit√≥rio de c√≥digo.
    * **Estrutura do Reposit√≥rio:** O c√≥digo foi organizado contendo:
        * `app.py`: O c√≥digo-fonte principal.
        * `requirements.txt`: Arquivo crucial contendo a lista de depend√™ncias (`streamlit`, `pandas`, `mysql-connector-python`) para que o servidor saiba o que instalar.
        * `image_7.png`: Recursos visuais (logomarca).
    * **Corre√ß√µes T√©cnicas:** Durante esta fase, ajustou-se a nomenclatura do arquivo principal para `app.py` (em min√∫sculo), atendendo aos requisitos de sistemas baseados em Linux, que diferenciam mai√∫sculas de min√∫sculas.

    #### 6. Etapa 5: Publica√ß√£o Online (Streamlit Cloud)
    A etapa final consistiu em colocar a aplica√ß√£o no ar.
    * **Integra√ß√£o CI/CD:** O **Streamlit Community Cloud** foi conectado ao reposit√≥rio do GitHub.
    * **Deploy:** Ao configurar o deploy, o servidor do Streamlit leu o arquivo `requirements.txt`, instalou as bibliotecas necess√°rias e executou o `app.py`.
    * **Resultado:** A aplica√ß√£o est√° agora 100% online, responsiva (adapt√°vel a celulares e computadores) e conectada em tempo real ao banco de dados, permitindo a demonstra√ß√£o da performance dos algoritmos de qualquer lugar.

    #### 7. Conclus√£o
    Este projeto integrou com sucesso os conceitos te√≥ricos de Estrutura de Dados com pr√°ticas modernas de Engenharia de Software e Cloud Computing. O resultado final evidencia claramente a superioridade do HashMap em velocidade, seguido pela Busca Indexada, provando a import√¢ncia da escolha correta das estruturas de dados no desenvolvimento de sistemas.
    """)

st.write("") 

# 3. C√ìDIGO FONTE (√öLTIMO)
if st.toggle("üíª Ver C√≥digo Fonte Python"):
    with open(__file__, "r", encoding='utf-8') as f:
        codigo = f.read()
    st.code(codigo, language="python")

